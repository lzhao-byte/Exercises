{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit ('gatech': conda)",
   "display_name": "Python 3.7.6 64-bit ('gatech': conda)",
   "metadata": {
    "interpreter": {
     "hash": "6c1155f863d4337240da029764ab92710ddb55e52734e0e03582fbcfef0cf508"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "#### Dataset: [SMS Spam Collection Data Set](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection)\n",
    "#### Method: Naive Bayes with Smoothing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "source": [
    "### Function Definition"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vocabulary in a list of string\n",
    "def get_voc(df, text_name = 'message'):\n",
    "    # get unique words\n",
    "    voc = ' '.join(df[text_name].values).lower() # change to lower case\n",
    "    voc = re.sub(r'[^\\w]',' ',voc).split() # remove symbols\n",
    "    voc = set([st.strip() for st in voc]) # unique words in the data set\n",
    "\n",
    "    # set of unique words in the data set\n",
    "    voc_ind = {v: k for k, v in enumerate(voc)} # word-index\n",
    "    ind_voc = {k: v for k, v in enumerate(voc)} # index-word\n",
    "\n",
    "    return voc\n",
    "\n",
    "# count words in a string\n",
    "def count_words(s):\n",
    "    prep   = re.sub(r'[^\\w]',' ',s.lower()).split()\n",
    "    counts = Counter(prep)\n",
    "    dicts  = {k: v for k, v in counts.items()}\n",
    "\n",
    "    return dicts\n",
    "\n",
    "# split data into train, test, with same class ratio\n",
    "def split_data(df, class_name = 'label', test_size = 0.2):\n",
    "    train_size = 1 - test_size\n",
    "    num_class = df[class_name].unique()\n",
    "    classes = [df[df[class_name] == c].reset_index(drop = True) for c in num_class]\n",
    "\n",
    "    train_index = [np.random.choice(len(c), int(len(c) * train_size), replace = False) for c in classes]\n",
    "    test_index = [list(set(range(len(classes[i]))) - set(train_index[i])) for i in range(len(train_index))]\n",
    "\n",
    "    train = pd.concat([classes[i].iloc[train_index[i], :] for i in range(len(train_index))])\n",
    "    test = pd.concat([classes[i].iloc[test_index[i], :] for i in range(len(test_index))])\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def learn_nb(df, voc, class_name = 'label', text_name = 'message'):\n",
    "    # vocabulary\n",
    "    voc_counts = len(voc)\n",
    "\n",
    "    # class counts\n",
    "    num_class = df[class_name].unique()\n",
    "    p_class = [len(df[df[class_name] == c]) / len(df) for c in num_class]\n",
    "\n",
    "    # word counts\n",
    "    p_words = []\n",
    "    for c in num_class:\n",
    "        texts = count_words(' '.join(df[df[class_name] == c][text_name].values))\n",
    "        counts_c = sum(texts.values())\n",
    "\n",
    "        p_word_c = {}\n",
    "        \n",
    "        for w in voc:\n",
    "            if w in texts:\n",
    "                p_word_c[w] = (texts[w] + 1 ) / (counts_c + voc_counts)\n",
    "            else:\n",
    "                p_word_c[w] = 1 / (counts_c + voc_counts)\n",
    "\n",
    "        p_words.append(p_word_c)\n",
    "\n",
    "    return num_class, p_class, p_words\n",
    "\n",
    "def apply_nb(df, classes, p_class, p_words, class_name = 'label', text_name = 'message'):\n",
    "    df['word_counts'] = df[text_name].apply(lambda x: count_words(x))\n",
    "    p_likelihood = [df['word_counts'].apply(lambda x: np.log(p_class[i]) + np.sum([np.log(p_words[i][k]) * v for k, v in x.items()])).values for i in range(len(classes))]\n",
    "    df['pred_label'] = np.argmax(p_likelihood, axis = 0)\n",
    "\n",
    "    return df\n",
    "\n",
    "def cal_acc(df, class_name = 'label', pred_class_name = 'pred_label'):\n",
    "    classes = df[class_name].unique()\n",
    "    overall_accuracy = len(df[df[class_name] == df[pred_class_name]]) / len(df)\n",
    "    class_accuracy = [len(df[(df[class_name] == c) & (df[class_name] == df[pred_class_name])]) / len(df[df[class_name] == c]) for c in classes]\n",
    "    \n",
    "    return overall_accuracy, class_accuracy"
   ]
  },
  {
   "source": [
    "### Test on the Data Set"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Overall Train Accuracy: 0.992\nClass 0 Accuracy: 0.997\nClass 1 Accuracy: 0.958\nOverall Test Accuracy: 0.985\nClass 0 Accuracy: 0.983\nClass 1 Accuracy: 0.993\n"
    }
   ],
   "source": [
    "# read data set \n",
    "df = pd.read_csv('SMSSpamCollection', delimiter = '\\t', header=None, names = ['class', 'message'])\n",
    "df['label'] = 0\n",
    "df.loc[df['class'] == 'spam','label'] = 1\n",
    "\n",
    "train, test = split_data(df)\n",
    "voc = get_voc(df)\n",
    "num_class, p_class, p_words = learn_nb(train, voc)\n",
    "\n",
    "# training\n",
    "pred_df = apply_nb(train, num_class, p_class, p_words)\n",
    "acc, class_acc = cal_acc(pred_df)\n",
    "\n",
    "print(\"Overall Train Accuracy: %.3f\" % acc)\n",
    "p = [print(\"Class %d Accuracy: %.3f\" % (c, class_acc[c])) for c in range(len(class_acc))]\n",
    "\n",
    "# test\n",
    "pred_df = apply_nb(test, num_class, p_class, p_words)\n",
    "acc, class_acc = cal_acc(pred_df)\n",
    "\n",
    "print(\"Overall Test Accuracy: %.3f\" % acc)\n",
    "p = [print(\"Class %d Accuracy: %.3f\" % (c, class_acc[c])) for c in range(len(class_acc))]"
   ]
  },
  {
   "source": [
    "### Compare with sklearn"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Test Accuracy: 0.987\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99       959\n           1       0.99      0.92      0.95       156\n\n    accuracy                           0.99      1115\n   macro avg       0.99      0.96      0.97      1115\nweighted avg       0.99      0.99      0.99      1115\n\n"
    }
   ],
   "source": [
    "# sklearn Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "x = df.message\n",
    "y = df.label\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "vectorizer = CountVectorizer()\n",
    "word_counts = vectorizer.fit_transform(x_train.values)\n",
    "\n",
    "classifer = MultinomialNB()\n",
    "classifer.fit(word_counts, y_train.values)\n",
    "\n",
    "test_count = vectorizer.transform(x_test.values)\n",
    "preds = classifer.predict(test_count)\n",
    "\n",
    "print(\"Test Accuracy: %.3f\" % accuracy_score(y_test.values, preds))\n",
    "print(classification_report(y_test.values, preds))"
   ]
  }
 ]
}